# yaml-language-server: $schema=values.schema.json

operatorNamespace: storage

pspEnable: true

csiDriverNamePrefix: storage

configOverride: |
  [global]
  mon_allow_pool_delete = true
  osd_pool_default_size = 2
  osd_pool_default_min_size = 1
  osd_crush_chooseleaf_type = 0

  [mds]
  mds_cache_trim_threshold = 524288

cephClusterSpec:
  mon:
    count: 3
    allowMultiplePerNode: true
  mgr:
    count: 2
    allowMultiplePerNode: true
  dashboard:
    enabled: true
    ssl: true
  crashCollector:
    disable: false
  logCollector:
    enabled: true
  network:
    connections:
      encryption:
        enabled: true
      compression:
        enabled: false
      requireMsgr2: false
  cleanupPolicy:
    allowUninstallWithVolumes: true
  removeOSDsIfOutAndSafeToRemove: true
  storage: # cluster level storage configuration and selection
    useAllNodes: true
    useAllDevices: true
  resources:
    mgr:
      limits:
        memory: "4Gi"
      requests:
        cpu: "500m"
        memory: "512Mi"
    mon:
      limits:
        memory: "8Gi"
      requests:
        cpu: "1000m"
        memory: "1Gi"
    osd:
      limits:
        memory: "8Gi"
      requests:
        cpu: "1000m"
        memory: "4Gi"
    prepareosd:
      requests:
        cpu: "500m"
        memory: "50Mi"
    mgr-sidecar:
      limits:
        memory: "1Gi"
      requests:
        cpu: "100m"
        memory: "40Mi"
    crashcollector:
      limits:
        memory: "400Mi"
      requests:
        cpu: "100m"
        memory: "60Mi"
    logcollector:
      limits:
        memory: "2Gi"
      requests:
        cpu: "100m"
        memory: "100Mi"
    cleanup:
      limits:
        memory: "1Gi"
      requests:
        cpu: "500m"
        memory: "100Mi"
    exporter:
      limits:
        memory: "128Mi"
      requests:
        cpu: "50m"
        memory: "50Mi"

cephBlockPools: []

cephFileSystemVolumeSnapshotClass:
  enabled: false

cephBlockPoolsVolumeSnapshotClass:
  enabled: false

cephFileSystems:
  - name: ceph-filesystem
    spec:
      metadataPool:
        failureDomain: osd
        replicated:
          size: 2
      dataPools:
        - failureDomain: osd
          replicated:
            size: 2
          name: cephfsdata0
      metadataServer:
        activeCount: 1
        activeStandby: true
        resources:
          limits:
            memory: "4Gi"
          requests:
            cpu: "1000m"
            memory: "4Gi"
        priorityClassName: system-cluster-critical
    storageClass:
      enabled: true
      isDefault: false
      name: ceph-fs
      pool: cephfsdata0
      reclaimPolicy: Delete
      allowVolumeExpansion: true
      volumeBindingMode: "Immediate"
      parameters:
        csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
        csi.storage.k8s.io/provisioner-secret-namespace: "{{ .Release.Namespace }}"
        csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
        csi.storage.k8s.io/controller-expand-secret-namespace: "{{ .Release.Namespace }}"
        csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
        csi.storage.k8s.io/node-stage-secret-namespace: "{{ .Release.Namespace }}"
        csi.storage.k8s.io/fstype: ext4

cephObjectStores:
  - name: ceph-objectstore
    spec:
      metadataPool:
        failureDomain: osd
        replicated:
          size: 2
      dataPool:
        failureDomain: osd
        replicated:
          size: 2
      preservePoolsOnDelete: false
      gateway:
        type: s3
        port: 80
        resources:
          limits:
            memory: "2Gi"
          requests:
            cpu: "1000m"
            memory: "1Gi"
        securePort: 443
        # sslCertificateRef:
        instances: 1
        priorityClassName: system-cluster-critical
    storageClass:
      enabled: true
      name: ceph-bucket
      provisioner: storage.ceph.rook.io/bucket
      reclaimPolicy: Delete
      volumeBindingMode: "Immediate"
      parameters:
        region: us-west-1
        objectStoreName: ceph-bucket
        objectStoreNamespace: storage
        bucketName: ceph-bucket
    ingress:
      enabled: false
      
cephECBlockPools:
  - name: ec-pool
    spec:
      metadataPool:
        failureDomain: osd
        replicated:
          size: 2
      dataPool:
        failureDomain: osd
        erasureCoded:
          dataChunks: 2
          codingChunks: 1
    parameters:
      clusterID: storage
      imageFormat: "2"
      imageFeatures: layering
      csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
      csi.storage.k8s.io/provisioner-secret-namespace: storage
      csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
      csi.storage.k8s.io/controller-expand-secret-namespace: storage
      csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
      csi.storage.k8s.io/node-stage-secret-namespace: storage
    storageClass:
      provisioner: storage.rbd.csi.ceph.com
      enabled: true
      name: ceph-block
      isDefault: false
      allowVolumeExpansion: true
      reclaimPolicy: Delete


